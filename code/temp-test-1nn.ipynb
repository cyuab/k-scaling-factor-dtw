{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c790c052",
   "metadata": {},
   "source": [
    "# DTW-based Nearest Neighbor Classification for Time Series\n",
    "\n",
    "This notebook implements Dynamic Time Warping (DTW) based nearest neighbor classification using the aeon library, following the experimental approach described in similarity measure research for time series data mining.\n",
    "\n",
    "## Overview\n",
    "We will:\n",
    "1. Load time series datasets using aeon\n",
    "2. Implement DTW-based 1-NN classification\n",
    "3. Compare performance with baseline methods\n",
    "4. Visualize results and DTW alignment behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bd7e40",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import necessary libraries including aeon for time series analysis, numpy for numerical operations, matplotlib for visualization, and sklearn for metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87664fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Aeon version available for time series analysis\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Aeon imports for time series analysis\n",
    "from aeon.datasets import load_classification\n",
    "from aeon.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from aeon.distances import dtw_distance, euclidean_distance\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Aeon version available for time series analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ea97ec",
   "metadata": {},
   "source": [
    "## 2. Load Time Series Dataset\n",
    "\n",
    "Load a UCR time series dataset using aeon's load_classification function, splitting into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40e9ffd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Coffee dataset...\n",
      "Error loading dataset: load_classification() got an unexpected keyword argument 'return_X_y'\n",
      "Trying alternative dataset...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "load_classification() got an unexpected keyword argument 'return_X_y'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     X_train, y_train = \u001b[43mload_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_X_y\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     X_test, y_test = load_classification(dataset_name, split=\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m, return_X_y=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: load_classification() got an unexpected keyword argument 'return_X_y'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTrying alternative dataset...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m dataset_name = \u001b[33m\"\u001b[39m\u001b[33mGunPoint\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m X_train, y_train = \u001b[43mload_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_X_y\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m X_test, y_test = load_classification(dataset_name, split=\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m, return_X_y=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m instead\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: load_classification() got an unexpected keyword argument 'return_X_y'"
     ]
    }
   ],
   "source": [
    "# Load Time Series Dataset\n",
    "# Using a classic UCR dataset - Coffee (small dataset good for demonstration)\n",
    "# You can change this to other datasets like 'GunPoint', 'TwoLeadECG', 'ArrowHead', etc.\n",
    "\n",
    "dataset_name = \"Coffee\"\n",
    "print(f\"Loading {dataset_name} dataset...\")\n",
    "\n",
    "try:\n",
    "    # Load the dataset\n",
    "    X_train, y_train = load_classification(dataset_name, split=\"train\", return_X_y=True)\n",
    "    X_test, y_test = load_classification(dataset_name, split=\"test\", return_X_y=True)\n",
    "\n",
    "    print(f\"Dataset loaded successfully!\")\n",
    "    print(f\"Training set shape: {X_train.shape}\")\n",
    "    print(f\"Test set shape: {X_test.shape}\")\n",
    "    print(f\"Training labels shape: {y_train.shape}\")\n",
    "    print(f\"Test labels shape: {y_test.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    print(\"Trying alternative dataset...\")\n",
    "    dataset_name = \"GunPoint\"\n",
    "    X_train, y_train = load_classification(dataset_name, split=\"train\", return_X_y=True)\n",
    "    X_test, y_test = load_classification(dataset_name, split=\"test\", return_X_y=True)\n",
    "    print(f\"Loaded {dataset_name} instead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cede0a1",
   "metadata": {},
   "source": [
    "## 3. Explore Dataset Properties\n",
    "\n",
    "Examine the dataset characteristics including number of samples, series length, number of classes, and visualize sample time series from different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f449152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Dataset Properties\n",
    "print(\"=== Dataset Properties ===\")\n",
    "print(f\"Dataset name: {dataset_name}\")\n",
    "print(f\"Number of training samples: {len(X_train)}\")\n",
    "print(f\"Number of test samples: {len(X_test)}\")\n",
    "print(f\"Time series length: {X_train.shape[1]}\")\n",
    "print(\n",
    "    f\"Number of features/dimensions: {X_train.shape[2] if len(X_train.shape) > 2 else 1}\"\n",
    ")\n",
    "\n",
    "# Examine class distribution\n",
    "unique_classes = np.unique(y_train)\n",
    "print(f\"Number of classes: {len(unique_classes)}\")\n",
    "print(f\"Class labels: {unique_classes}\")\n",
    "\n",
    "print(\"\\n=== Class Distribution ===\")\n",
    "train_class_counts = pd.Series(y_train).value_counts().sort_index()\n",
    "test_class_counts = pd.Series(y_test).value_counts().sort_index()\n",
    "\n",
    "print(\"Training set:\")\n",
    "for class_label in unique_classes:\n",
    "    count = train_class_counts.get(class_label, 0)\n",
    "    print(f\"  Class {class_label}: {count} samples\")\n",
    "\n",
    "print(\"Test set:\")\n",
    "for class_label in unique_classes:\n",
    "    count = test_class_counts.get(class_label, 0)\n",
    "    print(f\"  Class {class_label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b192d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample time series from different classes\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle(f\"Sample Time Series from {dataset_name} Dataset\", fontsize=16)\n",
    "\n",
    "# Plot samples from each class\n",
    "for i, class_label in enumerate(unique_classes[:4]):  # Show up to 4 classes\n",
    "    row, col = divmod(i, 2)\n",
    "    ax = axes[row, col] if len(unique_classes) > 1 else axes\n",
    "\n",
    "    # Get samples from this class\n",
    "    class_indices = np.where(y_train == class_label)[0]\n",
    "\n",
    "    # Plot multiple samples from this class\n",
    "    for j in range(min(5, len(class_indices))):  # Plot up to 5 samples\n",
    "        idx = class_indices[j]\n",
    "        if len(X_train.shape) == 3:\n",
    "            time_series = X_train[idx, :, 0]  # Take first dimension if multivariate\n",
    "        else:\n",
    "            time_series = X_train[idx, :]\n",
    "\n",
    "        ax.plot(time_series, alpha=0.7, linewidth=1.5)\n",
    "\n",
    "    ax.set_title(f\"Class {class_label} (n={len(class_indices)})\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Remove empty subplots if fewer than 4 classes\n",
    "if len(unique_classes) < 4:\n",
    "    for i in range(len(unique_classes), 4):\n",
    "        row, col = divmod(i, 2)\n",
    "        fig.delaxes(axes[row, col])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df99e0d7",
   "metadata": {},
   "source": [
    "## 4. Implement DTW-based Classification\n",
    "\n",
    "Create a 1-nearest neighbor classifier using DTW distance metric with aeon's KNeighborsTimeSeriesClassifier, exploring different DTW parameters like window constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3420fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement DTW-based Classification\n",
    "print(\"=== Setting up DTW-based Classifiers ===\")\n",
    "\n",
    "# DTW without window constraint (full DTW)\n",
    "dtw_classifier_full = KNeighborsTimeSeriesClassifier(\n",
    "    n_neighbors=1, distance=\"dtw\", distance_params=None  # No window constraint\n",
    ")\n",
    "\n",
    "# DTW with window constraint (Sakoe-Chiba band)\n",
    "# Window size as percentage of series length\n",
    "window_size = int(0.1 * X_train.shape[1])  # 10% of series length\n",
    "print(f\"Using window constraint of size: {window_size}\")\n",
    "\n",
    "dtw_classifier_constrained = KNeighborsTimeSeriesClassifier(\n",
    "    n_neighbors=1, distance=\"dtw\", distance_params={\"window\": window_size}\n",
    ")\n",
    "\n",
    "print(\"DTW classifiers created successfully!\")\n",
    "print(f\"Full DTW: No window constraint\")\n",
    "print(f\"Constrained DTW: Window size = {window_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda297ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DTW classifiers\n",
    "print(\"Training DTW classifiers...\")\n",
    "\n",
    "# Train full DTW classifier\n",
    "print(\"Training full DTW classifier...\")\n",
    "dtw_classifier_full.fit(X_train, y_train)\n",
    "print(\"Full DTW classifier trained!\")\n",
    "\n",
    "# Train constrained DTW classifier\n",
    "print(\"Training constrained DTW classifier...\")\n",
    "dtw_classifier_constrained.fit(X_train, y_train)\n",
    "print(\"Constrained DTW classifier trained!\")\n",
    "\n",
    "# Make predictions\n",
    "print(\"Making predictions...\")\n",
    "y_pred_dtw_full = dtw_classifier_full.predict(X_test)\n",
    "y_pred_dtw_constrained = dtw_classifier_constrained.predict(X_test)\n",
    "\n",
    "print(\"Predictions completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b710ae28",
   "metadata": {},
   "source": [
    "## 5. Evaluate Classification Performance\n",
    "\n",
    "Train the DTW classifier and evaluate its performance on the test set using accuracy, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1b709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Classification Performance\n",
    "print(\"=== DTW Classification Results ===\")\n",
    "\n",
    "# Calculate accuracies\n",
    "accuracy_dtw_full = accuracy_score(y_test, y_pred_dtw_full)\n",
    "accuracy_dtw_constrained = accuracy_score(y_test, y_pred_dtw_constrained)\n",
    "\n",
    "print(f\"Full DTW Accuracy: {accuracy_dtw_full:.4f} ({accuracy_dtw_full*100:.2f}%)\")\n",
    "print(\n",
    "    f\"Constrained DTW Accuracy: {accuracy_dtw_constrained:.4f} ({accuracy_dtw_constrained*100:.2f}%)\"\n",
    ")\n",
    "\n",
    "# Classification reports\n",
    "print(\"\\n=== Full DTW Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred_dtw_full))\n",
    "\n",
    "print(\"\\n=== Constrained DTW Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred_dtw_constrained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6ea3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Full DTW confusion matrix\n",
    "cm_full = confusion_matrix(y_test, y_pred_dtw_full)\n",
    "sns.heatmap(\n",
    "    cm_full,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=unique_classes,\n",
    "    yticklabels=unique_classes,\n",
    "    ax=axes[0],\n",
    ")\n",
    "axes[0].set_title(f\"Full DTW Confusion Matrix\\nAccuracy: {accuracy_dtw_full:.4f}\")\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"Actual\")\n",
    "\n",
    "# Constrained DTW confusion matrix\n",
    "cm_constrained = confusion_matrix(y_test, y_pred_dtw_constrained)\n",
    "sns.heatmap(\n",
    "    cm_constrained,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=unique_classes,\n",
    "    yticklabels=unique_classes,\n",
    "    ax=axes[1],\n",
    ")\n",
    "axes[1].set_title(\n",
    "    f\"Constrained DTW Confusion Matrix\\nAccuracy: {accuracy_dtw_constrained:.4f}\"\n",
    ")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"Actual\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8ec9fe",
   "metadata": {},
   "source": [
    "## 6. Compare with Baseline Methods\n",
    "\n",
    "Compare DTW performance against Euclidean distance-based nearest neighbor classification and analyze the differences in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9ab9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with Baseline Methods\n",
    "print(\"=== Implementing Baseline Methods ===\")\n",
    "\n",
    "# Euclidean distance-based 1-NN classifier using aeon\n",
    "euclidean_classifier = KNeighborsTimeSeriesClassifier(\n",
    "    n_neighbors=1, distance=\"euclidean\"\n",
    ")\n",
    "\n",
    "# Traditional sklearn 1-NN classifier (requires flattening the data)\n",
    "# Flatten the time series data for sklearn\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "sklearn_classifier = KNeighborsClassifier(n_neighbors=1, metric=\"euclidean\")\n",
    "\n",
    "print(\"Training baseline classifiers...\")\n",
    "\n",
    "# Train euclidean classifier\n",
    "euclidean_classifier.fit(X_train, y_train)\n",
    "y_pred_euclidean = euclidean_classifier.predict(X_test)\n",
    "\n",
    "# Train sklearn classifier\n",
    "sklearn_classifier.fit(X_train_flat, y_train)\n",
    "y_pred_sklearn = sklearn_classifier.predict(X_test_flat)\n",
    "\n",
    "print(\"Baseline classifiers trained and predictions made!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb07cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all methods\n",
    "print(\"=== Performance Comparison ===\")\n",
    "\n",
    "methods = {\n",
    "    \"Full DTW\": y_pred_dtw_full,\n",
    "    \"Constrained DTW\": y_pred_dtw_constrained,\n",
    "    \"Euclidean (aeon)\": y_pred_euclidean,\n",
    "    \"Euclidean (sklearn)\": y_pred_sklearn,\n",
    "}\n",
    "\n",
    "results = []\n",
    "for method_name, predictions in methods.items():\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    results.append({\"Method\": method_name, \"Accuracy\": accuracy})\n",
    "    print(f\"{method_name:20s}: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(\"Accuracy\", ascending=False)\n",
    "\n",
    "print(\"\\n=== Ranked Results ===\")\n",
    "for i, row in results_df.iterrows():\n",
    "    print(f\"{row['Method']:20s}: {row['Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d499b0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Bar plot of accuracies\n",
    "bars = plt.bar(\n",
    "    results_df[\"Method\"],\n",
    "    results_df[\"Accuracy\"],\n",
    "    color=[\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\"],\n",
    ")\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, accuracy in zip(bars, results_df[\"Accuracy\"]):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 0.005,\n",
    "        f\"{accuracy:.3f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.title(f\"Classification Accuracy Comparison on {dataset_name} Dataset\", fontsize=14)\n",
    "plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "plt.xlabel(\"Method\", fontsize=12)\n",
    "plt.ylim(0, 1.1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate improvement of best DTW over Euclidean\n",
    "best_dtw_acc = max(accuracy_dtw_full, accuracy_dtw_constrained)\n",
    "euclidean_acc = accuracy_score(y_test, y_pred_euclidean)\n",
    "improvement = ((best_dtw_acc - euclidean_acc) / euclidean_acc) * 100\n",
    "\n",
    "print(f\"\\nBest DTW improvement over Euclidean: {improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5b7e4",
   "metadata": {},
   "source": [
    "## 7. Visualize Results\n",
    "\n",
    "Create visualizations showing classification results, distance matrices, and alignment paths for selected time series pairs to demonstrate DTW behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Results - Sample Alignments\n",
    "print(\"=== Visualizing DTW Alignments ===\")\n",
    "\n",
    "# Select samples for demonstration\n",
    "# Find a correctly classified and a misclassified sample by DTW\n",
    "correct_predictions = np.where(y_pred_dtw_full == y_test)[0]\n",
    "incorrect_predictions = np.where(y_pred_dtw_full != y_test)[0]\n",
    "\n",
    "if len(incorrect_predictions) > 0:\n",
    "    sample_indices = [correct_predictions[0], incorrect_predictions[0]]\n",
    "    titles = [\"Correctly Classified\", \"Misclassified\"]\n",
    "else:\n",
    "    sample_indices = [correct_predictions[0], correct_predictions[1]]\n",
    "    titles = [\"Sample 1\", \"Sample 2\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle(\"DTW Alignment Examples\", fontsize=16)\n",
    "\n",
    "for idx, (sample_idx, title) in enumerate(zip(sample_indices, titles)):\n",
    "    # Get test sample\n",
    "    if len(X_test.shape) == 3:\n",
    "        test_sample = X_test[sample_idx, :, 0]\n",
    "    else:\n",
    "        test_sample = X_test[sample_idx, :]\n",
    "\n",
    "    true_label = y_test[sample_idx]\n",
    "    predicted_label = y_pred_dtw_full[sample_idx]\n",
    "\n",
    "    # Find nearest neighbor in training set\n",
    "    min_distance = float(\"inf\")\n",
    "    nearest_idx = 0\n",
    "\n",
    "    for train_idx in range(len(X_train)):\n",
    "        if len(X_train.shape) == 3:\n",
    "            train_sample = X_train[train_idx, :, 0]\n",
    "        else:\n",
    "            train_sample = X_train[train_idx, :]\n",
    "\n",
    "        distance = dtw_distance(test_sample, train_sample)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            nearest_idx = train_idx\n",
    "\n",
    "    # Get nearest neighbor\n",
    "    if len(X_train.shape) == 3:\n",
    "        nearest_sample = X_train[nearest_idx, :, 0]\n",
    "    else:\n",
    "        nearest_sample = X_train[nearest_idx, :]\n",
    "\n",
    "    nearest_label = y_train[nearest_idx]\n",
    "\n",
    "    # Plot the time series\n",
    "    ax1 = axes[idx, 0]\n",
    "    ax1.plot(test_sample, label=f\"Test (True: {true_label})\", linewidth=2)\n",
    "    ax1.plot(\n",
    "        nearest_sample,\n",
    "        label=f\"Nearest (Label: {nearest_label})\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    ax1.set_title(f\"{title}\\nPred: {predicted_label}, DTW Distance: {min_distance:.3f}\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Create a simple alignment visualization\n",
    "    ax2 = axes[idx, 1]\n",
    "\n",
    "    # Create a heatmap showing the distance matrix (simplified)\n",
    "    len1, len2 = len(test_sample), len(nearest_sample)\n",
    "    dist_matrix = np.zeros((len1, len2))\n",
    "\n",
    "    for i in range(len1):\n",
    "        for j in range(len2):\n",
    "            dist_matrix[i, j] = abs(test_sample[i] - nearest_sample[j])\n",
    "\n",
    "    im = ax2.imshow(dist_matrix, cmap=\"viridis\", aspect=\"auto\")\n",
    "    ax2.set_title(\"Distance Matrix\")\n",
    "    ax2.set_xlabel(\"Nearest Neighbor Index\")\n",
    "    ax2.set_ylabel(\"Test Sample Index\")\n",
    "    plt.colorbar(im, ax=ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97785ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary and Analysis\n",
    "print(\"=== Final Analysis Summary ===\")\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Time series length: {X_train.shape[1]}\")\n",
    "print(f\"Number of classes: {len(unique_classes)}\")\n",
    "\n",
    "print(\"\\n=== Performance Summary ===\")\n",
    "for i, row in results_df.iterrows():\n",
    "    print(f\"{row['Method']:20s}: {row['Accuracy']:.4f} ({row['Accuracy']*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n=== Key Findings ===\")\n",
    "best_method = results_df.iloc[0][\"Method\"]\n",
    "best_accuracy = results_df.iloc[0][\"Accuracy\"]\n",
    "print(f\"• Best performing method: {best_method} with {best_accuracy:.4f} accuracy\")\n",
    "\n",
    "dtw_methods = results_df[results_df[\"Method\"].str.contains(\"DTW\")]\n",
    "if len(dtw_methods) > 1:\n",
    "    full_dtw_acc = results_df[results_df[\"Method\"] == \"Full DTW\"][\"Accuracy\"].iloc[0]\n",
    "    const_dtw_acc = results_df[results_df[\"Method\"] == \"Constrained DTW\"][\n",
    "        \"Accuracy\"\n",
    "    ].iloc[0]\n",
    "\n",
    "    if full_dtw_acc > const_dtw_acc:\n",
    "        print(\n",
    "            f\"• Full DTW outperformed constrained DTW by {(full_dtw_acc - const_dtw_acc)*100:.2f}%\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            f\"• Constrained DTW outperformed full DTW by {(const_dtw_acc - full_dtw_acc)*100:.2f}%\"\n",
    "        )\n",
    "\n",
    "euclidean_acc = results_df[results_df[\"Method\"] == \"Euclidean (aeon)\"][\"Accuracy\"].iloc[\n",
    "    0\n",
    "]\n",
    "best_dtw_acc = max(accuracy_dtw_full, accuracy_dtw_constrained)\n",
    "\n",
    "if best_dtw_acc > euclidean_acc:\n",
    "    improvement = ((best_dtw_acc - euclidean_acc) / euclidean_acc) * 100\n",
    "    print(f\"• DTW showed {improvement:.1f}% improvement over Euclidean distance\")\n",
    "else:\n",
    "    decline = ((euclidean_acc - best_dtw_acc) / euclidean_acc) * 100\n",
    "    print(f\"• Euclidean distance outperformed DTW by {decline:.1f}%\")\n",
    "\n",
    "print(f\"\\n=== Experiment Complete ===\")\n",
    "print(\"This notebook demonstrates DTW-based nearest neighbor classification\")\n",
    "print(\"for time series data, following experimental methodologies from\")\n",
    "print(\"similarity measure research in time series data mining.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ksfdtw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
