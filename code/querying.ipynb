{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "112c03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported Python files do not automatically reload after you modify them\n",
    "# M1: Automatically Reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# M2: Manual Reload\n",
    "# import importlib\n",
    "# import ksfdtw\n",
    "# importlib.reload(ksfdtw)\n",
    "\n",
    "# https://stackoverflow.com/questions/20309456/how-do-i-call-a-function-from-another-py-file\n",
    "from ksfdtw import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85b7e46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cyuab/miniconda3/envs/ksfdtw/lib/python3.12/site-packages/tslearn/bases/bases.py:15: UserWarning: h5py not installed, hdf5 features will not be supported.\n",
      "Install h5py to use hdf5 features: http://docs.h5py.org/\n",
      "  warn(h5py_msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tslearn.metrics import dtw, lb_keogh\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tslearn.neighbors import KNeighborsTimeSeriesClassifier\n",
    "from tslearn.metrics import dtw as tsln_dtw\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109bffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A neat way to load the dataset\n",
    "# data = np.load(\"../data/gunpoint_preprocessed.npz\")\n",
    "# data_dict = {key: data[key] for key in data.files}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a94579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A old way to load the dataset\n",
    "data = np.load(\"../data/gunpoint_preprocessed.npz\", allow_pickle=True)\n",
    "X_train_scaled = data[\"X_train_scaled\"]\n",
    "X_train_proc = data[\"X_train_proc\"]\n",
    "X_train_proc_noise = data[\"X_train_proc_noise\"]\n",
    "y_train = data[\"y_train\"]\n",
    "X_test_scaled = data[\"X_test_scaled\"]\n",
    "X_test_proc = data[\"X_test_proc\"]\n",
    "X_test_proc_noisy = data[\"X_test_proc_noisy\"]\n",
    "y_test = data[\"y_test\"]\n",
    "train_cutting_orig = data[\"train_cutting_orig\"].tolist()\n",
    "train_cutting_final = data[\"train_cutting_final\"].tolist()\n",
    "test_cutting_orig = data[\"test_cutting_orig\"].tolist()\n",
    "test_cutting_final = data[\"test_cutting_final\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d6ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Euclidean distances to all training samples\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "413889e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(X_train_proc[0])\n",
    "n = len(X_train_scaled[0])\n",
    "l = 2\n",
    "L = int(np.floor(min(np.ceil(l*m),n)/3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b60990",
   "metadata": {},
   "source": [
    "Applying PSDTW to compute the distance profile of each time series from $\\mathcal{D}_{\\text{train, ps}}$ to every time series in $\\mathcal{D}_{\\text{train}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6015748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps\n",
    "results = []\n",
    "for i in range(0,50): # X_train_proc.shape[0]\n",
    "    results.append([ps_distance_p(X_train_proc[i], x, 2, 0.1, 10, 3, distance_method='dtw', lower_bound_method=lb_kim_fl) for x in X_train_scaled[:50]])\n",
    "np.savez(\"../results/results.npz\", results=np.array(results, dtype=object))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c3fc9",
   "metadata": {},
   "source": [
    "Applying PSDTW to compute the distance profile of each time series from $\\mathcal{D}_{\\text{train, ps, noise}}$ to every time series in $\\mathcal{D}_{\\text{train}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad304350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps + noise\n",
    "results_noise = []\n",
    "for i in range(0,50): # X_train_proc.shape[0]\n",
    "    results_noise.append([ps_distance_p(X_train_proc_noisy[i], x, 2, 0.1, 10, 3, distance_method='dtw', lower_bound_method=lb_kim_fl) for x in X_train_scaled])\n",
    "np.savez(\"../results/results_noise.npz\", results=np.array(results_noise, dtype=object))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a6231c",
   "metadata": {},
   "source": [
    "To check the pruning power, we use the theoretical tightest lower bound $LB_{Shen}$. However, the running time of it may not be the fastest as the computation time of $LB_{Shen}$ is higher than those losse lower bound that are computational cheap.\n",
    "$LB_{Kim\\_FL}$, which only consider the first point pair and the last point pair to construct the lower bound, run exceptionally fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8187f7c",
   "metadata": {},
   "source": [
    "Applying PSDTW to compute the distance profile of each time series from $\\mathcal{D}_{\\text{train, ps}}$[:10] to every time series in $\\mathcal{D}_{\\text{train}}[:10]$ with the theoretical tightest lower bound $LB_{Shen}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1bc9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps\n",
    "# Check the pruning power\n",
    "results_lb_shen = []\n",
    "\n",
    "for i in range(0,10): # X_train_proc.shape[0]\n",
    "    results_lb_shen.append([ps_distance_p(X_train_proc[i], x, 2, 0.1, 10, 3, distance_method='dtw', lower_bound_method=lb_shen) for x in X_train_scaled[:10]])\n",
    "    # print(i)\n",
    "np.savez(\"../results/results_lb_shen.npz\", results=np.array(results_lb_shen, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f4f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps + noise\n",
    "# Check the pruning power\n",
    "results_lb_shen_noise = []\n",
    "\n",
    "for i in range(0,10): # X_train_proc.shape[0]\n",
    "    results_lb_shen_noise.append([ps_distance_p(X_train_proc_noisy[i], x, 2, 0.1, 10, 3, distance_method='dtw', lower_bound_method=lb_shen) for x in X_train_scaled[:10]])\n",
    "    # print(i)\n",
    "np.savez(\"../results/results_lb_shen_noise.npz\", results=np.array(results_lb_shen_noise, dtype=object))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975b17b3",
   "metadata": {},
   "source": [
    "Applying PSDTW to compute the distance profile of each time series from $\\mathcal{D}_{\\text{train, ps}}$[:10] to every time series in $\\mathcal{D}_{\\text{train}}[:10]$ without using any lower bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e62f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps\n",
    "results_no_prune = []\n",
    "for i in range(0,10): # X_train_proc.shape[0]\n",
    "    results_no_prune.append([ps_distance_p_without_prune(X_train_proc[i], x, 2, 0.1, 10, 3, distance_method='dtw', lower_bound_method=lb_dummy) for x in X_train_scaled[:10]])\n",
    "    # print(i)\n",
    "np.savez(\"../results/results_no_prune.npz\", results=np.array(results_no_prune, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c3d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps + noise\n",
    "results_no_prune_noise = []\n",
    "for i in range(0,10): # X_train_proc.shape[0]\n",
    "    results_no_prune_noise.append([ps_distance_p_without_prune(X_train_proc_noisy[i], x, 2, 0.1, 10, 3, distance_method='dtw', lower_bound_method=lb_dummy) for x in X_train_scaled[:10]])\n",
    "    # print(i)\n",
    "np.savez(\"../results/results_no_prune_noise.npz\", results=np.array(results_no_prune_noise, dtype=object))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4131d9c5",
   "metadata": {},
   "source": [
    "# Pruning Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee622ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3985237\n"
     ]
    }
   ],
   "source": [
    "# ps\n",
    "# No prune\n",
    "total_no_iterations =0\n",
    "for i in range(0,10):\n",
    "     # cuts = [r[1] for r in results[i]]\n",
    "     iterations = np.array([r[2] for r in results_no_prune[i]])\n",
    "     total_no_iterations += sum(iterations)  \n",
    "     # best_idx = np.argmin(distances)\n",
    "     # if i != best_idx:\n",
    "     #      print(i, \"cannot retrieve the original time series\")\n",
    "print(total_no_iterations)\n",
    "total_no_iterations_no_prune = total_no_iterations\n",
    "# 3985237\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d987dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4023811\n"
     ]
    }
   ],
   "source": [
    "# ps + noise\n",
    "# No prune\n",
    "total_no_iterations =0\n",
    "for i in range(0,10):\n",
    "     # cuts = [r[1] for r in results[i]]\n",
    "     iterations = np.array([r[2] for r in results_no_prune2[i]])\n",
    "     total_no_iterations += sum(iterations)  \n",
    "     # best_idx = np.argmin(distances)\n",
    "     # if i != best_idx:\n",
    "     #      print(i, \"cannot retrieve the original time series\")\n",
    "print(total_no_iterations)\n",
    "total_no_iterations_no_prune = total_no_iterations\n",
    "# 4023811\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16628f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1404294\n"
     ]
    }
   ],
   "source": [
    "# ps\n",
    "# Using LB_Shen\n",
    "total_no_iterations =0\n",
    "for i in range(0,10):\n",
    "     # cuts = [r[1] for r in results[i]]\n",
    "     iterations = np.array([r[2] for r in results_lb_shen[i]])\n",
    "     total_no_iterations += sum(iterations)  \n",
    "     # best_idx = np.argmin(distances)\n",
    "     # if i != best_idx:\n",
    "     #      print(i, \"cannot retrieve the original time series\")\n",
    "print(total_no_iterations)\n",
    "total_no_iterations_lb_shen = total_no_iterations\n",
    "# 1404294"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef2a814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1483516\n"
     ]
    }
   ],
   "source": [
    "# ps + noise\n",
    "# Using LB_Shen\n",
    "total_no_iterations =0\n",
    "for i in range(0,10):\n",
    "     # cuts = [r[1] for r in results[i]]\n",
    "     iterations = np.array([r[2] for r in results_lb_shen2[i]])\n",
    "     total_no_iterations += sum(iterations)  \n",
    "     # best_idx = np.argmin(distances)\n",
    "     # if i != best_idx:\n",
    "     #      print(i, \"cannot retrieve the original time series\")\n",
    "print(total_no_iterations)\n",
    "total_no_iterations_lb_shen = total_no_iterations\n",
    "# 1483516"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3ac7fc",
   "metadata": {},
   "source": [
    "Compute how many of distance measures have been pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2e478d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6313156855528255)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(total_no_iterations_no_prune - total_no_iterations_lb_shen)/total_no_iterations_no_prune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7b3e12",
   "metadata": {},
   "source": [
    "# Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18f427e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(distances, true_index, k):\n",
    "    # Get the indices of the top-k smallest distances\n",
    "    top_k_indices = sorted(range(len(distances)), key=lambda x: distances[x])[:k]\n",
    "    \n",
    "    # Check if the true match is among them\n",
    "    return 1 if true_index in top_k_indices else 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cf06e0",
   "metadata": {},
   "source": [
    "Compute $P@k$ for querying $Q \\in \\mathcal{D}_{\\text{train, ps}}$ using PSDTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "287eef65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.96 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# PSDTW\n",
    "precision_at_1, precision_at_3, precision_at_5, precision_at_7 = 0, 0, 0, 0\n",
    "for i in range(0,50):\n",
    "     distances = np.array([r[0] for r in results[i]])\n",
    "     precision_at_1 += precision_at_k(distances, i, 1)\n",
    "     precision_at_3 += precision_at_k(distances, i, 3)\n",
    "     precision_at_5 += precision_at_k(distances, i, 5)\n",
    "     precision_at_7 += precision_at_k(distances, i, 7)\n",
    "     # cuts = [r[1] for r in results[i]]\n",
    "     # iterations = np.array([r[2] for r in results[i]])  \n",
    "     # best_idx = np.argmin(distances)\n",
    "     # if i != best_idx:\n",
    "     #      print(i, \"cannot retrieve the original time series\")\n",
    "print(precision_at_1/50, precision_at_3/50, precision_at_5/50, precision_at_7/50) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6193a6",
   "metadata": {},
   "source": [
    "Compute $P@k$ for querying $Q \\in \\mathcal{D}_{\\text{train, ps, noise}}$ using PSDTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b769c267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48 0.82 0.96 1.0\n"
     ]
    }
   ],
   "source": [
    "# PSDTW, noisy\n",
    "precision_at_1, precision_at_3, precision_at_5, precision_at_7 = 0, 0, 0, 0\n",
    "for i in range(0,50):\n",
    "     distances = np.array([r[0] for r in results_noise[i]])\n",
    "     precision_at_1 += precision_at_k(distances, i, 1)\n",
    "     precision_at_3 += precision_at_k(distances, i, 3)\n",
    "     precision_at_5 += precision_at_k(distances, i, 5)\n",
    "     precision_at_7 += precision_at_k(distances, i, 7)\n",
    "     # cuts = [r[1] for r in results[i]]\n",
    "     # iterations = np.array([r[2] for r in results[i]])  \n",
    "     # best_idx = np.argmin(distances)\n",
    "     # if i != best_idx:\n",
    "     #      print(i, \"cannot retrieve the original time series\")\n",
    "print(precision_at_1/50, precision_at_3/50, precision_at_5/50, precision_at_7/50) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd429beb",
   "metadata": {},
   "source": [
    "Compute $P@k$ for querying $Q \\in \\mathcal{D}_{\\text{train, ps}}$ using DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9aa6d22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 37 43 45\n",
      "0.48 0.74 0.86 0.9\n"
     ]
    }
   ],
   "source": [
    "# DTW\n",
    "precision_at_1, precision_at_3, precision_at_5, precision_at_7 = 0, 0, 0, 0\n",
    "for i in range(0,50):\n",
    "    distances = np.array([tsln_dtw(X_train_proc[i], x) for x in X_train_scaled])\n",
    "    precision_at_1 += precision_at_k(distances, i, 1)\n",
    "    precision_at_3 += precision_at_k(distances, i, 3)\n",
    "    precision_at_5 += precision_at_k(distances, i, 5)\n",
    "    precision_at_7 += precision_at_k(distances, i, 7)\n",
    "print(precision_at_1, precision_at_3, precision_at_5, precision_at_7)\n",
    "print(precision_at_1/50, precision_at_3/50, precision_at_5/50, precision_at_7/50)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c041b3a",
   "metadata": {},
   "source": [
    "Compute $P@k$ for querying $Q \\in \\mathcal{D}_{\\text{train, ps, noise}}$ using DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f8b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 32 39 43\n",
      "0.44 0.64 0.78 0.86\n"
     ]
    }
   ],
   "source": [
    "# DTW Noise\n",
    "precision_at_1, precision_at_3, precision_at_5, precision_at_7 = 0, 0, 0, 0\n",
    "for i in range(0,50):\n",
    "    distances = np.array([tsln_dtw(X_train_proc_noisy[i], x) for x in X_train_scaled])\n",
    "    precision_at_1 += precision_at_k(distances, i, 1)\n",
    "    precision_at_3 += precision_at_k(distances, i, 3)\n",
    "    precision_at_5 += precision_at_k(distances, i, 5)\n",
    "    precision_at_7 += precision_at_k(distances, i, 7)\n",
    "print(precision_at_1, precision_at_3, precision_at_5, precision_at_7)\n",
    "print(precision_at_1/50, precision_at_3/50, precision_at_5/50, precision_at_7/50)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd722594",
   "metadata": {},
   "source": [
    "Compute $P@k$ for querying $Q \\in \\mathcal{D}_{\\text{train, ps}}$ using ED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d749a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 5 9\n",
      "0.02 0.06 0.1 0.18\n"
     ]
    }
   ],
   "source": [
    "# ED\n",
    "precision_at_1, precision_at_3, precision_at_5, precision_at_7 = 0, 0, 0, 0\n",
    "for i in range(0,50):\n",
    "    distances = np.array([euclidean_distance(X_train_proc[i], x) for x in X_train_scaled])\n",
    "    precision_at_1 += precision_at_k(distances, i, 1)\n",
    "    precision_at_3 += precision_at_k(distances, i, 3)\n",
    "    precision_at_5 += precision_at_k(distances, i, 5)\n",
    "    precision_at_7 += precision_at_k(distances, i, 7)\n",
    "print(precision_at_1, precision_at_3, precision_at_5, precision_at_7)\n",
    "print(precision_at_1/50, precision_at_3/50, precision_at_5/50, precision_at_7/50)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0f5bd5",
   "metadata": {},
   "source": [
    "Compute $P@k$ for querying $Q \\in \\mathcal{D}_{\\text{train, ps, noise}}$ using ED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53448fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 4 9\n",
      "0.02 0.06 0.08 0.18\n"
     ]
    }
   ],
   "source": [
    "# ED\n",
    "precision_at_1, precision_at_3, precision_at_5, precision_at_7 = 0, 0, 0, 0\n",
    "for i in range(0,50):\n",
    "    distances = np.array([euclidean_distance(X_train_proc_noisy[i], x) for x in X_train_scaled])\n",
    "    precision_at_1 += precision_at_k(distances, i, 1)\n",
    "    precision_at_3 += precision_at_k(distances, i, 3)\n",
    "    precision_at_5 += precision_at_k(distances, i, 5)\n",
    "    precision_at_7 += precision_at_k(distances, i, 7)\n",
    "print(precision_at_1, precision_at_3, precision_at_5, precision_at_7)\n",
    "print(precision_at_1/50, precision_at_3/50, precision_at_5/50, precision_at_7/50)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26cb0865",
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ksfdtw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
