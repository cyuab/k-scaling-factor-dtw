{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from ksfdtw import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85b7e46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cyuab/miniconda3/envs/ksfdtw/lib/python3.12/site-packages/tslearn/bases/bases.py:15: UserWarning: h5py not installed, hdf5 features will not be supported.\n",
      "Install h5py to use hdf5 features: http://docs.h5py.org/\n",
      "  warn(h5py_msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tslearn.metrics import dtw, lb_keogh\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tslearn.neighbors import KNeighborsTimeSeriesClassifier\n",
    "from tslearn.metrics import dtw as tsln_dtw\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109bffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A neat way to load the dataset\n",
    "# data = np.load(\"../data/gunpoint_preprocessed.npz\")\n",
    "# data_dict = {key: data[key] for key in data.files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a94579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A old way to load the dataset\n",
    "data = np.load(\"../data/gunpoint_preprocessed.npz\", allow_pickle=True)\n",
    "X_train_scaled = data[\"X_train_scaled\"]\n",
    "X_train_proc = data[\"X_train_proc\"]\n",
    "X_train_proc_noise = data[\"X_train_proc_noise\"]\n",
    "y_train = data[\"y_train\"]\n",
    "X_test_scaled = data[\"X_test_scaled\"]\n",
    "X_test_proc = data[\"X_test_proc\"]\n",
    "X_test_proc_noisy = data[\"X_test_proc_noise\"]\n",
    "y_test = data[\"y_test\"]\n",
    "train_cutting_orig = data[\"train_cutting_orig\"].tolist()\n",
    "train_cutting_final = data[\"train_cutting_final\"].tolist()\n",
    "test_cutting_orig = data[\"test_cutting_orig\"].tolist()\n",
    "test_cutting_final = data[\"test_cutting_final\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d6ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Euclidean distances to all training samples\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413889e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(X_train_proc[0])\n",
    "n = len(X_train_scaled[0])\n",
    "l = 2\n",
    "L = int(np.floor(min(np.ceil(l * m), n) / 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b60990",
   "metadata": {},
   "source": [
    "Applying PSDTW to compute the distance profile of each time series from $\\mathcal{D}_{\\text{train, ps}}$ to every time series in $\\mathcal{D}_{\\text{train}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6015748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps\n",
    "results = []\n",
    "for i in range(0, 50):  # X_train_proc.shape[0]\n",
    "    results.append(\n",
    "        [\n",
    "            ps_distance_p(\n",
    "                X_train_proc[i],\n",
    "                x,\n",
    "                2,\n",
    "                0.1,\n",
    "                10,\n",
    "                3,\n",
    "                distance_method=\"dtw\",\n",
    "                lower_bound_method=lb_kim_fl,\n",
    "            )\n",
    "            for x in X_train_scaled[:50]\n",
    "        ]\n",
    "    )\n",
    "    # print(i)\n",
    "np.savez(\"../results/results.npz\", results=np.array(results, dtype=object))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c3fc9",
   "metadata": {},
   "source": [
    "Applying PSDTW to compute the distance profile of each time series from $\\mathcal{D}_{\\text{train, ps, noise}}$ to every time series in $\\mathcal{D}_{\\text{train}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad304350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps + noise\n",
    "results_noise = []\n",
    "for i in range(0, 50):  # X_train_proc.shape[0]\n",
    "    results_noise.append(\n",
    "        [\n",
    "            ps_distance_p(\n",
    "                X_train_proc_noise[i],\n",
    "                x,\n",
    "                2,\n",
    "                0.1,\n",
    "                10,\n",
    "                3,\n",
    "                distance_method=\"dtw\",\n",
    "                lower_bound_method=lb_kim_fl,\n",
    "            )\n",
    "            for x in X_train_scaled\n",
    "        ]\n",
    "    )\n",
    "    # print(i)\n",
    "np.savez(\"../results/results_noise.npz\", results=np.array(results_noise, dtype=object))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a6231c",
   "metadata": {},
   "source": [
    "To check the pruning power, we use the theoretical tightest lower bound $LB_{Shen}$. However, the running time of it may not be the fastest as the computation time of $LB_{Shen}$ is higher than those losse lower bound that are computational cheap.\n",
    "$LB_{Kim\\_FL}$, which only consider the first point pair and the last point pair to construct the lower bound, run exceptionally fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8187f7c",
   "metadata": {},
   "source": [
    "Applying PSDTW to compute the distance profile of each time series from $\\mathcal{D}_{\\text{train, ps}}$[:10] ($\\mathcal{D}_{\\text{train, ps, noise}}$[:10]) to every time series in $\\mathcal{D}_{\\text{train}}[:10]$ with the theoretical tightest lower bound $LB_{Shen}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bc9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps\n",
    "# Check the pruning power\n",
    "results_lb_shen = []\n",
    "\n",
    "for i in range(0, 10):  # X_train_proc.shape[0]\n",
    "    results_lb_shen.append(\n",
    "        [\n",
    "            ps_distance_p(\n",
    "                X_train_proc[i],\n",
    "                x,\n",
    "                2,\n",
    "                0.1,\n",
    "                10,\n",
    "                3,\n",
    "                distance_method=\"dtw\",\n",
    "                lower_bound_method=lb_shen,\n",
    "            )\n",
    "            for x in X_train_scaled[:10]\n",
    "        ]\n",
    "    )\n",
    "    # print(i)\n",
    "np.savez(\n",
    "    \"../results/results_lb_shen.npz\", results=np.array(results_lb_shen, dtype=object)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f4f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps + noise\n",
    "# Check the pruning power\n",
    "results_lb_shen_noise = []\n",
    "\n",
    "for i in range(0, 10):  # X_train_proc.shape[0]\n",
    "    results_lb_shen_noise.append(\n",
    "        [\n",
    "            ps_distance_p(\n",
    "                X_train_proc_noise[i],\n",
    "                x,\n",
    "                2,\n",
    "                0.1,\n",
    "                10,\n",
    "                3,\n",
    "                distance_method=\"dtw\",\n",
    "                lower_bound_method=lb_shen,\n",
    "            )\n",
    "            for x in X_train_scaled[:10]\n",
    "        ]\n",
    "    )\n",
    "    # print(i)\n",
    "np.savez(\n",
    "    \"../results/results_lb_shen_noise.npz\",\n",
    "    results=np.array(results_lb_shen_noise, dtype=object),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975b17b3",
   "metadata": {},
   "source": [
    "Applying PSDTW to compute the distance profile of each time series from $\\mathcal{D}_{\\text{train, ps}}$[:10] $\\mathcal{D}_{\\text{train, ps, noise}}$[:10] to every time series in $\\mathcal{D}_{\\text{train}}[:10]$ without using any lower bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e62f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps\n",
    "results_no_prune = []\n",
    "for i in range(0, 10):  # X_train_proc.shape[0]\n",
    "    results_no_prune.append(\n",
    "        [\n",
    "            ps_distance_p_without_prune(\n",
    "                X_train_proc[i],\n",
    "                x,\n",
    "                2,\n",
    "                0.1,\n",
    "                10,\n",
    "                3,\n",
    "                distance_method=\"dtw\",\n",
    "                lower_bound_method=lb_dummy,\n",
    "            )\n",
    "            for x in X_train_scaled[:10]\n",
    "        ]\n",
    "    )\n",
    "    # print(i)\n",
    "np.savez(\n",
    "    \"../results/results_no_prune.npz\", results=np.array(results_no_prune, dtype=object)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c3d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps + noise\n",
    "results_no_prune_noise = []\n",
    "for i in range(0, 10):  # X_train_proc.shape[0]\n",
    "    results_no_prune_noise.append(\n",
    "        [\n",
    "            ps_distance_p_without_prune(\n",
    "                X_train_proc_noise[i],\n",
    "                x,\n",
    "                2,\n",
    "                0.1,\n",
    "                10,\n",
    "                3,\n",
    "                distance_method=\"dtw\",\n",
    "                lower_bound_method=lb_dummy,\n",
    "            )\n",
    "            for x in X_train_scaled[:10]\n",
    "        ]\n",
    "    )\n",
    "    # print(i)\n",
    "np.savez(\n",
    "    \"../results/results_no_prune_noise.npz\",\n",
    "    results=np.array(results_no_prune_noise, dtype=object),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7b3e12",
   "metadata": {},
   "source": [
    "# Precision@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f427e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(distances, true_index, k):\n",
    "    # Get the indices of the top-k smallest distances\n",
    "    top_k_indices = sorted(range(len(distances)), key=lambda x: distances[x])[:k]\n",
    "\n",
    "    # Check if the true match is among them\n",
    "    return 1 if true_index in top_k_indices else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cf06e0",
   "metadata": {},
   "source": [
    "Compute $P@k$ for querying $Q \\in \\mathcal{D}_{\\text{train, ps}}$ using PSDTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287eef65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 0.96 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# PSDTW\n",
    "precision_at_1, precision_at_3, precision_at_5, precision_at_7 = 0, 0, 0, 0\n",
    "for i in range(0, 50):\n",
    "    distances = np.array([r[0] for r in results[i]])\n",
    "    precision_at_1 += precision_at_k(distances, i, 1)\n",
    "    precision_at_3 += precision_at_k(distances, i, 3)\n",
    "    precision_at_5 += precision_at_k(distances, i, 5)\n",
    "    precision_at_7 += precision_at_k(distances, i, 7)\n",
    "    # cuts = [r[1] for r in results[i]]\n",
    "    # iterations = np.array([r[2] for r in results[i]])\n",
    "    # best_idx = np.argmin(distances)\n",
    "    # if i != best_idx:\n",
    "    #      print(i, \"cannot retrieve the original time series\")\n",
    "print(\n",
    "    precision_at_1 / 50, precision_at_3 / 50, precision_at_5 / 50, precision_at_7 / 50\n",
    ")\n",
    "# 0.8 0.96 1.0 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6193a6",
   "metadata": {},
   "source": [
    "Compute $P@k$ for querying $Q \\in \\mathcal{D}_{\\text{train, ps, noise}}$ using PSDTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b769c267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58 0.88 0.92 0.96\n"
     ]
    }
   ],
   "source": [
    "# PSDTW, noisy\n",
    "precision_at_1, precision_at_3, precision_at_5, precision_at_7 = 0, 0, 0, 0\n",
    "for i in range(0, 50):\n",
    "    distances = np.array([r[0] for r in results_noise[i]])\n",
    "    precision_at_1 += precision_at_k(distances, i, 1)\n",
    "    precision_at_3 += precision_at_k(distances, i, 3)\n",
    "    precision_at_5 += precision_at_k(distances, i, 5)\n",
    "    precision_at_7 += precision_at_k(distances, i, 7)\n",
    "    # cuts = [r[1] for r in results[i]]\n",
    "    # iterations = np.array([r[2] for r in results[i]])\n",
    "    # best_idx = np.argmin(distances)\n",
    "    # if i != best_idx:\n",
    "    #      print(i, \"cannot retrieve the original time series\")\n",
    "print(\n",
    "    precision_at_1 / 50, precision_at_3 / 50, precision_at_5 / 50, precision_at_7 / 50\n",
    ")\n",
    "# 0.48 0.82 0.96 1.0\n",
    "# 0.58 0.88 0.92 0.96 <- The updated version has a slightly different result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c108a9",
   "metadata": {},
   "source": [
    "# Analyzing Pruning Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424261b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3985237\n"
     ]
    }
   ],
   "source": [
    "# ps\n",
    "# No prune\n",
    "total_no_iterations = 0\n",
    "for i in range(0, 10):\n",
    "    # cuts = [r[1] for r in results[i]]\n",
    "    iterations = np.array([r[2] for r in results_no_prune[i]])\n",
    "    total_no_iterations += sum(iterations)\n",
    "    # best_idx = np.argmin(distances)\n",
    "    # if i != best_idx:\n",
    "    #      print(i, \"cannot retrieve the original time series\")\n",
    "print(total_no_iterations)\n",
    "# 3985237\n",
    "total_no_iterations_no_prune = total_no_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4fcb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1404294\n"
     ]
    }
   ],
   "source": [
    "# ps\n",
    "# Using LB_Shen\n",
    "total_no_iterations = 0\n",
    "for i in range(0, 10):\n",
    "    # cuts = [r[1] for r in results[i]]\n",
    "    iterations = np.array([r[2] for r in results_lb_shen[i]])\n",
    "    total_no_iterations += sum(iterations)\n",
    "    # best_idx = np.argmin(distances)\n",
    "    # if i != best_idx:\n",
    "    #      print(i, \"cannot retrieve the original time series\")\n",
    "print(total_no_iterations)\n",
    "total_no_iterations_lb_shen = total_no_iterations\n",
    "# 1404294"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227d202c",
   "metadata": {},
   "source": [
    "Compute how many of distance measures have been pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14350b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6476259755693325)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    total_no_iterations_no_prune - total_no_iterations_lb_shen\n",
    ") / total_no_iterations_no_prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c340c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4031567\n"
     ]
    }
   ],
   "source": [
    "# ps + noise\n",
    "# No prune\n",
    "total_no_iterations = 0\n",
    "for i in range(0, 10):\n",
    "    # cuts = [r[1] for r in results[i]]\n",
    "    iterations = np.array([r[2] for r in results_no_prune_noise[i]])\n",
    "    total_no_iterations += sum(iterations)\n",
    "    # best_idx = np.argmin(distances)\n",
    "    # if i != best_idx:\n",
    "    #      print(i, \"cannot retrieve the original time series\")\n",
    "print(total_no_iterations)\n",
    "total_no_iterations_no_prune = total_no_iterations\n",
    "# 4023811\n",
    "# 4031567 <- The updated version has a slightly different result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af5a2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1497458\n"
     ]
    }
   ],
   "source": [
    "# ps + noise\n",
    "# Using LB_Shen\n",
    "total_no_iterations = 0\n",
    "for i in range(0, 10):\n",
    "    # cuts = [r[1] for r in results[i]]\n",
    "    iterations = np.array([r[2] for r in results_lb_shen_noise[i]])\n",
    "    total_no_iterations += sum(iterations)\n",
    "    # best_idx = np.argmin(distances)\n",
    "    # if i != best_idx:\n",
    "    #      print(i, \"cannot retrieve the original time series\")\n",
    "print(total_no_iterations)\n",
    "total_no_iterations_lb_shen = total_no_iterations\n",
    "# 1483516\n",
    "# 1497458 <- The updated version has a slightly different result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19bf1dd",
   "metadata": {},
   "source": [
    "Compute how many of distance measures have been pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b251e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.628566758285302)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    total_no_iterations_no_prune - total_no_iterations_lb_shen\n",
    ") / total_no_iterations_no_prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26cb0865",
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ksfdtw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
